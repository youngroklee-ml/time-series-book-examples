[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Examples in Time Series Analysis and Application",
    "section": "",
    "text": "Preface\nThis is a R implementation of examples in “Time Series Analysis and Application” by Chi-Hyuck Jun.\n\nBook: 시계열 분석 및 응용\nData download: 자유아카데미 자료실",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "ch01_smoothing.html",
    "href": "ch01_smoothing.html",
    "title": "1  Smoothing",
    "section": "",
    "text": "1.1 Example 1.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.1",
    "href": "ch01_smoothing.html#example-1.1",
    "title": "1  Smoothing",
    "section": "",
    "text": "1.1.1 Data\nCreate a data frame.\n\nforest_fire &lt;- tribble(\n  ~year, ~cnt,\n  2006, 369,\n  2007, 418,\n  2008, 389,\n  2009, 570,\n  2010, 282,\n  2011, 277,\n  2012, 197,\n  2013, 296,\n  2014, 492,\n  2015, 623,\n  2016, 391\n)\n\n\n\n1.1.2 Convert to time-series data\nConvert the data frame to time series data frame (tsibble) object. You must set index with a column that represents timepoints for the series. Please note that tsibble automatically notice that the index is year and that the series is regular yearly series.\n\nforest_fire_ts &lt;-\n  forest_fire |&gt;\n  as_tsibble(index = year)\n\nforest_fire_ts\n\n# A tsibble: 11 x 2 [1Y]\n    year   cnt\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  2006   369\n 2  2007   418\n 3  2008   389\n 4  2009   570\n 5  2010   282\n 6  2011   277\n 7  2012   197\n 8  2013   296\n 9  2014   492\n10  2015   623\n11  2016   391\n\n\n\n\n1.1.3 Moving average\nCompute moving average by calling slider::slide_mean(). Set complete = TRUE to return missing value NA when there are missing observations in the sliding window.\n\nforest_fire_ma &lt;-\n  forest_fire_ts |&gt;\n  mutate(\n    ma3 = slider::slide_mean(cnt, before = 2, after = 0, complete = TRUE),\n    ma6 = slider::slide_mean(cnt, before = 5, after = 0, complete = TRUE)\n  )\n\nforest_fire_ma\n\n# A tsibble: 11 x 4 [1Y]\n    year   cnt   ma3   ma6\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2006   369   NA    NA \n 2  2007   418   NA    NA \n 3  2008   389  392    NA \n 4  2009   570  459    NA \n 5  2010   282  414.   NA \n 6  2011   277  376.  384.\n 7  2012   197  252   356.\n 8  2013   296  257.  335.\n 9  2014   492  328.  352.\n10  2015   623  470.  361.\n11  2016   391  502   379.\n\n\n\n\n\n\n\n\nNote\n\n\n\n{slider} package provides functions to conduct rolling analysis using window functions. slide_*() function family is useful for time series with regular observations (i.e. no missing time period) as in this example. If your time series appear to be irregular, slide_index_*() function family would be useful.\n\n\nNow, forest_fire_ma is a time series data frame with three series: original value cnt, 3-yr moving average ma3, and 6-yr moving average ma6.\n\n\n1.1.4 Visualization\nCovert this to a long form by calling pivot_longer(). The resulting time series data frame will have key that is a label of each series.\n\nforest_fire_ma_long &lt;- \n  forest_fire_ma |&gt;\n  pivot_longer(c(cnt, ma3, ma6), names_to = \"statistics\")\n\nforest_fire_ma_long\n\n# A tsibble: 33 x 3 [1Y]\n# Key:       statistics [3]\n    year statistics value\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1  2006 cnt          369\n 2  2006 ma3           NA\n 3  2006 ma6           NA\n 4  2007 cnt          418\n 5  2007 ma3           NA\n 6  2007 ma6           NA\n 7  2008 cnt          389\n 8  2008 ma3          392\n 9  2008 ma6           NA\n10  2009 cnt          570\n# ℹ 23 more rows\n\n\nVisualize time series data. Call autoplot() with measurement variable name to draws line plot by each key.\n\nforest_fire_ma_long |&gt; \n  autoplot(value)\n\nWarning: Removed 7 rows containing missing values or values outside the scale range\n(`geom_line()`).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.2",
    "href": "ch01_smoothing.html#example-1.2",
    "title": "1  Smoothing",
    "section": "1.2 Example 1.2",
    "text": "1.2 Example 1.2\n\n1.2.1 Load data\n\nhousehold &lt;- \n  read_excel(\"data/J01.xlsx\", skip = 1) |&gt; \n  rename(cnt = `#households`)\n\n\n\n1.2.2 Convert to time-series data\n\nhousehold_ts &lt;-\n  household |&gt; \n  as_tsibble(index = year)\n\nhousehold_ts\n\n# A tsibble: 18 x 2 [1Y]\n    year   cnt\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  2000  2255\n 2  2001  2438\n 3  2002  2628\n 4  2003  2818\n 5  2004  3001\n 6  2005  3186\n 7  2006  3378\n 8  2007  3571\n 9  2008  3766\n10  2009  3963\n11  2010  4174\n12  2011  4380\n13  2012  4563\n14  2013  4756\n15  2014  4965\n16  2015  5179\n17  2016  5382\n18  2017  5562\n\n\n\n\n1.2.3 Train/test split\n\nhousehold_ts_train &lt;-\n  household_ts |&gt; \n  filter(year &lt;= 2014)\n\nhousehold_ts_test &lt;-\n  household_ts |&gt; \n  filter(year &gt; 2014)\n\n\n\n1.2.4 Double moving average with N = 4\n\nN &lt;- 4\n\nhousehold_double_ma &lt;-\n  household_ts_train |&gt; \n  mutate(\n    ma = slider::slide_mean(cnt, before = N - 1, after = 0, complete = TRUE),\n    ma_double = slider::slide_mean(ma, before = N - 1, after = 0, complete = TRUE)\n  )\n\nhousehold_double_ma\n\n# A tsibble: 15 x 4 [1Y]\n    year   cnt    ma ma_double\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1  2000  2255   NA        NA \n 2  2001  2438   NA        NA \n 3  2002  2628   NA        NA \n 4  2003  2818 2535.       NA \n 5  2004  3001 2721.       NA \n 6  2005  3186 2908.       NA \n 7  2006  3378 3096.     2815 \n 8  2007  3571 3284      3002.\n 9  2008  3766 3475.     3191.\n10  2009  3963 3670.     3381.\n11  2010  4174 3868.     3574.\n12  2011  4380 4071.     3771 \n13  2012  4563 4270      3970.\n14  2013  4756 4468.     4169.\n15  2014  4965 4666      4369.\n\n\nVisualize results.\n\nhousehold_double_ma |&gt; \n  pivot_longer(c(cnt, ma, ma_double), names_to = \"statistics\") |&gt; \n  autoplot(value)\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n1.2.5 Estimate a slope\nTake the latest moving average and double moving average.\n\nlatest &lt;- \n  household_double_ma |&gt; \n  slice_tail(n = 1)\n\nlatest\n\n# A tsibble: 1 x 4 [1Y]\n   year   cnt    ma ma_double\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1  2014  4965  4666     4369.\n\n\nCompute a slope\n\nb &lt;- (latest$ma - latest$ma_double) / (N - 1) * 2\nb\n\n[1] 198.1667\n\n\n\n\n1.2.6 Prediction\n\nhousehold_ts_test |&gt; \n  mutate(\n    ma = latest$ma,\n    ma_double = 2 * latest$ma - latest$ma_double + (year - latest$year) * b\n  )\n\n# A tsibble: 3 x 4 [1Y]\n   year   cnt    ma ma_double\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1  2015  5179  4666     5161.\n2  2016  5382  4666     5360.\n3  2017  5562  4666     5558.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#examples-1.3---1.4",
    "href": "ch01_smoothing.html#examples-1.3---1.4",
    "title": "1  Smoothing",
    "section": "1.3 Examples 1.3 - 1.4",
    "text": "1.3 Examples 1.3 - 1.4\n\n1.3.1 Load data\n\npatent &lt;- \n  read_excel(\"data/J02.xlsx\") |&gt; \n  rename(cnt = `#patents`)\n\n\n\n1.3.2 Convert to time-series data\n\npatent_ts &lt;-\n  patent |&gt; \n  as_tsibble(index = year)\n\npatent_ts\n\n# A tsibble: 24 x 2 [1Y]\n    year   cnt\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  1993  21.5\n 2  1994  28.6\n 3  1995  59.2\n 4  1996  68.4\n 5  1997  67.3\n 6  1998  50.6\n 7  1999  56  \n 8  2000  72.8\n 9  2001  73.7\n10  2002  76.6\n# ℹ 14 more rows\n\n\n\n\n1.3.3 Train/test split\n\npatent_ts_train &lt;-\n  patent_ts |&gt; \n  filter(year &lt;= 2013)\n\npatent_ts_test &lt;- \n  patent_ts |&gt; \n  filter(year &gt; 2013)\n\n\n\n1.3.4 Example 1.3: Double exponential smoothing with \\(\\alpha = 0.2\\)\n\n1.3.4.1 Smoothing on training data\n\nalpha &lt;- 0.2\n\nets_step &lt;- function(x, y, alpha) {\n  stopifnot(alpha &gt;= 0)\n  stopifnot(alpha &lt;= 1)\n  (1 - alpha) * x + alpha * y\n}\n\npatent_ets &lt;- \n  patent_ts_train |&gt; \n  mutate(\n    es = accumulate(cnt, ets_step, alpha = alpha),\n    es_double = accumulate(es, ets_step, alpha = alpha)\n  )\n\npatent_ets\n\n# A tsibble: 21 x 4 [1Y]\n    year   cnt    es es_double\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1  1993  21.5  21.5      21.5\n 2  1994  28.6  22.9      21.8\n 3  1995  59.2  30.2      23.5\n 4  1996  68.4  37.8      26.3\n 5  1997  67.3  43.7      29.8\n 6  1998  50.6  45.1      32.9\n 7  1999  56    47.3      35.7\n 8  2000  72.8  52.4      39.1\n 9  2001  73.7  56.6      42.6\n10  2002  76.6  60.6      46.2\n# ℹ 11 more rows\n\n\nVisualize the smoothing results.\n\npatent_ets |&gt; \n  pivot_longer(c(cnt, es, es_double), names_to = \"statistics\") |&gt; \n  autoplot(value)\n\n\n\n\n\n\n\n\n\n\n1.3.4.2 Estimate coefficients\nTake the last training time point.\n\nlatest &lt;- \n  patent_ets |&gt; \n  slice_tail(n = 1)\n\nn_train &lt;- nrow(patent_ets)\nlatest_year &lt;- latest$year\n\nEstimate slope b.\n\nb &lt;- alpha / (1 - alpha) * (latest$es - latest$es_double)\nb\n\n[1] 5.851673\n\n\nEstimate constant c.\n\nc &lt;- 2 * latest$es - latest$es_double - b * n_train\nc\n\n[1] 32.22202\n\n\n\n\n1.3.4.3 Prediction\n\npatent_ts_test |&gt; \n  mutate(\n    forecast = c + b * (n_train + (year - latest_year)),\n    forecast_error = cnt - forecast\n  )\n\n# A tsibble: 3 x 4 [1Y]\n   year   cnt forecast forecast_error\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1  2014  164.     161.          3.14 \n2  2015  167.     167.          0.489\n3  2016  163.     173.         -9.26 \n\n\n\n\n\n1.3.5 Example 1.4: Holt’s linear trend method\n\n1.3.5.1 Smoothing on training data\nImplement a function to update L and b in each iteration (i.e. each additional observation).\n\nholt_step &lt;- function(param, x, alpha, beta) {\n  L &lt;- param$L\n  b &lt;- param$b\n\n  L_new = alpha * x + (1 - alpha) * (L + b)\n  b_new = beta * (L_new - L) + (1 - beta) * b\n\n  res &lt;- list(L = L_new, b = b_new)\n\n  res\n}\n\nSet parameters for Holt smoothing.\n\nalpha &lt;- 0.2\nbeta &lt;- 0.2\n\nInitialize L and b values.\n\nL1 &lt;- patent_ts_train$cnt[1]\nb1 &lt;- patent_ts_train$cnt[2] - patent_ts_train$cnt[1]\n\nCompute Holt smoothing over training time periods.\n\npatent_holt &lt;- \n  patent_ts_train |&gt; \n  mutate(\n    es_double = accumulate(patent_ts_train$cnt[-1], holt_step, .init = list(L = L1, b = b1), alpha = alpha, beta = beta)\n  ) |&gt; \n  unnest_wider(es_double) |&gt; \n  as_tsibble(index = year)\n\npatent_holt\n\n# A tsibble: 21 x 4 [1Y]\n    year   cnt     L     b\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1993  21.5  21.5  7.1 \n 2  1994  28.6  28.6  7.1 \n 3  1995  59.2  40.4  8.04\n 4  1996  68.4  52.4  8.84\n 5  1997  67.3  62.5  9.08\n 6  1998  50.6  67.4  8.24\n 7  1999  56    71.7  7.46\n 8  2000  72.8  77.9  7.20\n 9  2001  73.7  82.8  6.75\n10  2002  76.6  87.0  6.23\n# ℹ 11 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nunnest_wider() returns tibble object, not tsibble object. sCall as_tsibble() to convert the results back to tsibble object.\n\n\nVisualize smoothing results.\n\npatent_holt |&gt; \n  pivot_longer(c(cnt, L), names_to = \"statistics\") |&gt; \n  autoplot(value)\n\n\n\n\n\n\n\n\n\n\n1.3.5.2 Prediction\nObtain the latest value of L and b.\n\nlatest &lt;- \n  patent_holt |&gt; \n  slice_tail(n = 1)\n\nlatest\n\n# A tsibble: 1 x 4 [1Y]\n   year   cnt     L     b\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2013   160  157.  5.84\n\n\nMake a prediction on test data with linear trend assumption.\n\npatent_ts_test |&gt; \n  mutate(\n    forecast = latest$L + latest$b * (year - latest$year),\n    forecast_error = cnt - forecast\n  )\n\n# A tsibble: 3 x 4 [1Y]\n   year   cnt forecast forecast_error\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1  2014  164.     163.          0.955\n2  2015  167.     169.         -1.68 \n3  2016  163.     175.        -11.4  \n\n\n\n\n\n1.3.6 Use fable::ETS()\nLet us use ETS() from {fable}. The function name stands for Error-Trend-Seasonality. The approach is explained in Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos.\nSmoothing parameters alpha within ETS() is the same to what we used in the previous section, but beta within ETS() is different from it of the previous chapter. In the following equations, \\(\\beta^{*}\\) is beta used in the previous section, while \\(\\beta = \\alpha \\beta^{*}\\) is beta in ETS().\n\\[\n\\begin{eqnarray*}\nl_t &=& \\alpha y_t + (1 - \\alpha)(l_{t - 1} + b_{t - 1})\\\\\nb_t &=& \\beta^{*}(l_t - l_{t - 1}) + (1 - \\beta^{*})b_{t - 1}\\\\\n    &=& \\beta^{*}((y_t + (1 - \\alpha)(l_{t - 1} + b_{t - 1})) - l_{t - 1}) + (1 - \\beta^{*})b_{t - 1}\\\\\n    &=& b_{t - 1} + \\alpha \\beta^{*} (y_t - l_{t - 1} - b_{t - 1})\\\\\n    &=& b_{t - 1} + \\beta \\varepsilon_t\n\\end{eqnarray*}\n\\]\nwhere \\(\\beta = \\alpha \\beta^{*}\\) and \\(\\varepsilon_t = y_t - l_{t - 1} - b_{t - 1}\\).\n\nalpha &lt;- 0.2\nbeta &lt;- 0.2\n\nfit &lt;- \n  patent_ts_train |&gt; \n  model(AAN = ETS(cnt ~ error(\"A\") + trend(\"A\", alpha = alpha, beta = alpha * beta) + season(\"N\")))\n\naugment(fit)\n\n# A tsibble: 21 x 6 [1Y]\n# Key:       .model [1]\n   .model  year   cnt .fitted .resid .innov\n   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 AAN     1993  21.5    31.0  -9.49  -9.49\n 2 AAN     1994  28.6    35.1  -6.53  -6.53\n 3 AAN     1995  59.2    39.6  19.6   19.6 \n 4 AAN     1996  68.4    50.1  18.3   18.3 \n 5 AAN     1997  67.3    61.0   6.27   6.27\n 6 AAN     1998  50.6    69.8 -19.2  -19.2 \n 7 AAN     1999  56      72.8 -16.8  -16.8 \n 8 AAN     2000  72.8    75.5  -2.71  -2.71\n 9 AAN     2001  73.7    81.0  -7.26  -7.26\n10 AAN     2002  76.6    85.2  -8.61  -8.61\n# ℹ 11 more rows\n\n\nLet us print estimated levels and slopes in training data\n\nfit$AAN[[1]]$fit$states\n\n# A tsibble: 22 x 3 [1Y]\n    year     l     b\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1992  24.6  6.41\n 2  1993  29.1  6.04\n 3  1994  33.8  5.77\n 4  1995  43.5  6.56\n 5  1996  53.7  7.29\n 6  1997  62.3  7.54\n 7  1998  66.0  6.77\n 8  1999  69.4  6.10\n 9  2000  75.0  5.99\n10  2001  79.5  5.70\n# ℹ 12 more rows\n\n\nThe results are still slightly different from previous section, because of different initialization of level and slope parameter value.\n\nfit |&gt; \n  select(AAN) |&gt; \n  report()\n\nSeries: cnt \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.2 \n    beta  = 0.04 \n\n  Initial states:\n     l[0]     b[0]\n 24.57432 6.414945\n\n  sigma^2:  158.923\n\n     AIC     AICc      BIC \n171.9343 173.3461 175.0679 \n\n\nLet us create a forecast.\n\nfit |&gt; \n  forecast(h = 3)\n\n# A fable: 3 x 4 [1Y]\n# Key:     .model [1]\n  .model  year         cnt .mean\n  &lt;chr&gt;  &lt;dbl&gt;      &lt;dist&gt; &lt;dbl&gt;\n1 AAN     2014 N(163, 159)  163.\n2 AAN     2015 N(169, 168)  169.\n3 AAN     2016 N(175, 181)  175.\n\n\nNow, call ETS() without specifying alpha and beta argument, so it finds the optimal value for fitting.\n\nfit_opt &lt;- \n  patent_ts_train |&gt; \n  model(AAN = ETS(cnt ~ error(\"A\") + trend(\"A\") + season(\"N\")))\n\nfitted(fit_opt)\n\n# A tsibble: 21 x 3 [1Y]\n# Key:       .model [1]\n   .model  year .fitted\n   &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 AAN     1993    25.1\n 2 AAN     1994    29.2\n 3 AAN     1995    36.3\n 4 AAN     1996    66.9\n 5 AAN     1997    76.1\n 6 AAN     1998    75.0\n 7 AAN     1999    58.3\n 8 AAN     2000    63.7\n 9 AAN     2001    80.5\n10 AAN     2002    81.4\n# ℹ 11 more rows\n\n\nCheck the optimized smoothing paramters and initial states.\n\nfit_opt |&gt; \n  select(AAN) |&gt; \n  report()\n\nSeries: cnt \nModel: ETS(A,A,N) \n  Smoothing parameters:\n    alpha = 0.9998999 \n    beta  = 0.0001008157 \n\n  Initial states:\n     l[0]     b[0]\n 17.45165 7.664263\n\n  sigma^2:  103.6232\n\n     AIC     AICc      BIC \n166.9535 170.9535 172.1761 \n\n\nLet us visualize estimated level, slope, and errors in the training data.\n\nfit_opt |&gt; \n  components() |&gt; \n  autoplot()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nMake forecast for next three years.\n\nfit_opt |&gt; \n  forecast(h = 3)\n\n# A fable: 3 x 4 [1Y]\n# Key:     .model [1]\n  .model  year         cnt .mean\n  &lt;chr&gt;  &lt;dbl&gt;      &lt;dist&gt; &lt;dbl&gt;\n1 AAN     2014 N(168, 104)  168.\n2 AAN     2015 N(175, 207)  175.\n3 AAN     2016 N(183, 311)  183.\n\n\nAnd visualize the forecast.\n\nfit_opt |&gt; \n  forecast(h = 3) |&gt; \n  autoplot(patent_ts_train)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.5",
    "href": "ch01_smoothing.html#example-1.5",
    "title": "1  Smoothing",
    "section": "1.4 Example 1.5",
    "text": "1.4 Example 1.5\n\n1.4.1 Load data\n\ngas_consumption &lt;- read_excel(\"data/J03.xlsx\", skip = 1) |&gt; \n  fill(year, .direction = \"down\") |&gt; \n  rename(consumption = comsumption) # fix typo in column name\n\ngas_consumption\n\n# A tibble: 84 × 3\n    year month consumption\n   &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;\n 1  2011     1        2006\n 2  2011     2        1620\n 3  2011     3        1354\n 4  2011     4         956\n 5  2011     5         560\n 6  2011     6         317\n 7  2011     7         254\n 8  2011     8         214\n 9  2011     9         231\n10  2011    10         482\n# ℹ 74 more rows\n\n\n\n\n1.4.2 Convert to tsibble object\n\ngas_consumption_ts &lt;- \n  gas_consumption |&gt; \n  mutate(year_month = make_yearmonth(year, month), .before = 1L) |&gt; \n  select(!c(year, month)) |&gt; \n  as_tsibble(index = year_month)\n\ngas_consumption_ts\n\n# A tsibble: 84 x 2 [1M]\n   year_month consumption\n        &lt;mth&gt;       &lt;dbl&gt;\n 1   2011 Jan        2006\n 2   2011 Feb        1620\n 3   2011 Mar        1354\n 4   2011 Apr         956\n 5   2011 May         560\n 6   2011 Jun         317\n 7   2011 Jul         254\n 8   2011 Aug         214\n 9   2011 Sep         231\n10   2011 Oct         482\n# ℹ 74 more rows\n\n\n\n\n1.4.3 Visualize seasonal pattern\nCall gg_season() from {feasts} package to visualize seasonal pattern of the variable of interest.\n\ngas_consumption_ts |&gt; \n  gg_season(consumption)\n\n\n\n\n\n\n\n\n\n\n1.4.4 Train/test data split\n\ngas_consumption_ts_train &lt;- \n  gas_consumption_ts |&gt; \n  filter(year_month &lt; make_yearmonth(2017, 1))\n\ngas_consumption_ts_test &lt;- \n  gas_consumption_ts |&gt; \n  filter(year_month &gt;= make_yearmonth(2017, 1))\n\n\n\n1.4.5 Holt-Winters’ multiplicative method\n\n1.4.5.1 Initialization\nExtract first 2 years data.\n\nm &lt;- 12\nr &lt;- 2\n\ngas_consumption_ts_init &lt;-\n  gas_consumption_ts_train |&gt; \n  slice_head(n = m * r)\n\nCompute an initial slope parameter value.\n\nb &lt;- \n  gas_consumption_ts_init |&gt; \n  mutate(slope = difference(consumption, lag = 12) / m) |&gt; \n  pull(slope) |&gt; \n  mean(na.rm= TRUE)\n\nb\n\n[1] -0.09722222\n\n\nCompute initial seasonal factor values.\n\ns &lt;-\n  gas_consumption_ts_init |&gt; \n  group_by(year(year_month)) |&gt; \n  mutate(seasonal = consumption / mean(consumption)) |&gt; \n  group_by(month(year_month)) |&gt; \n  mutate(seasonal = mean(seasonal)) |&gt; \n  ungroup() |&gt; \n  select(year_month, consumption, seasonal) |&gt; \n  slice_head(n = m) |&gt; \n  pull(seasonal)\n\ns\n\n [1] 2.2464249 1.9630622 1.6071974 1.1113816 0.5965731 0.3463274 0.2816907\n [8] 0.2336523 0.2739944 0.5426311 0.9887110 1.8083540\n\n\nCompute initial level.\n\nl &lt;- mean(gas_consumption_ts_init$consumption)\nl\n\n[1] 843.0833\n\n\n\n\n1.4.5.2 Smoothing on training data\n\nn_train &lt;- nrow(gas_consumption_ts_train)\nb_vec &lt;- vector(\"numeric\", length = m + n_train)\ns_vec &lt;- vector(\"numeric\", length = m + n_train)\nl_vec &lt;- vector(\"numeric\", length = m + n_train)\nx_vec &lt;- vector(\"numeric\", length = m + n_train)\n\nb_vec[m] &lt;- b\ns_vec[1:m] &lt;- s\nl_vec[m] &lt;- l\nx_vec[m + seq_len(n_train)] &lt;- gas_consumption_ts_train$consumption\n\n\nalpha &lt;- 0.1\nbeta &lt;- 0.1\ngamma &lt;- 0.1\n\nfor (t in (m + 1):length(b_vec)) {\n  l_vec[t] &lt;- alpha * x_vec[t] / s_vec[t - m] + (1 - alpha) * (l_vec[t - 1] + b_vec[t - 1])\n  b_vec[t] &lt;- beta * (l_vec[t] - l_vec[t - 1]) + (1 - beta) * b_vec[t - 1]\n  s_vec[t] &lt;- gamma * (x_vec[t] / l_vec[t]) + (1 - gamma) * s_vec[t - m]\n}\n\n\ngas_consumption_winters &lt;- \n  gas_consumption_ts_train |&gt; \n  mutate(\n    l = l_vec[-seq_len(m)],\n    b = b_vec[-seq_len(m)],\n    s = s_vec[-seq_len(m)]\n  )\n\ngas_consumption_winters |&gt; \n  tail(n = m)\n\n# A tsibble: 12 x 5 [1M]\n   year_month consumption     l       b     s\n        &lt;mth&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1   2016 Jan        1759  772. -0.365  2.24 \n 2   2016 Feb        1669  781.  0.487  1.97 \n 3   2016 Mar        1330  786.  1.02   1.60 \n 4   2016 Apr         781  780.  0.284  1.08 \n 5   2016 May         456  778.  0.0291 0.602\n 6   2016 Jun         283  781.  0.381  0.349\n 7   2016 Jul         238  788.  1.01   0.284\n 8   2016 Aug         181  786.  0.687  0.238\n 9   2016 Sep         211  785.  0.544  0.273\n10   2016 Oct         378  779. -0.152  0.524\n11   2016 Nov         908  791.  1.10   1.02 \n12   2016 Dec        1452  793.  1.17   1.82 \n\n\n\n\n1.4.5.3 Forecast\n\nl_latest &lt;- \n  gas_consumption_winters |&gt; \n  slice_tail(n = 1) |&gt; \n  pull(l)\n\nb_latest &lt;- \n  gas_consumption_winters |&gt; \n  slice_tail(n = 1) |&gt; \n  pull(b)\n\ns_latest &lt;- \n  gas_consumption_winters |&gt; \n  slice_tail(n = m) |&gt; \n  pull(s)\n\nmonth_latest &lt;- \n  gas_consumption_winters |&gt; \n  slice_tail(n = 1) |&gt; \n  pull(year_month)\n\n\ngas_consumption_winters_forecast &lt;- \n  gas_consumption_ts_test |&gt; \n  mutate(\n    k = year_month - month_latest,\n    forecast = (l_latest + b_latest * k) * s_latest[(k - 1) %% m + 1],\n    forecast_error = consumption - forecast\n  )\n\ngas_consumption_winters_forecast\n\n# A tsibble: 12 x 5 [1M]\n   year_month consumption     k forecast forecast_error\n        &lt;mth&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1   2017 Jan        1763     1    1779.         -15.9 \n 2   2017 Feb        1729     2    1563.         166.  \n 3   2017 Mar        1335     3    1277.          58.1 \n 4   2017 Apr         849     4     865.         -16.2 \n 5   2017 May         438     5     481.         -43.0 \n 6   2017 Jun         294     6     280.          14.5 \n 7   2017 Jul         223     7     227.          -4.36\n 8   2017 Aug         194     8     191.           2.88\n 9   2017 Sep         238     9     219.          18.8 \n10   2017 Oct         393    10     421.         -28.3 \n11   2017 Nov         970    11     821.         149.  \n12   2017 Dec        1811    12    1467.         344.  \n\n\n\n\n\n1.4.6 Use fable::ETS()\nHolt-Winters’ method can also be implemented in ETS() by specifying season() component. Here, set the multiplicative model that was specified in the previous section. ETS() for Holt-Winters’ method is is explained in Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos.\ngamma parameter in ETS() is slightly different from gamma parameter in the previous section. Let \\(\\gamma^{*}\\) be the gamma in the previous section and \\(\\gamma\\) be the gamma in ETS().\n\\[\n\\begin{eqnarray*}\ns_t &=& \\gamma^{*}\\frac{y_t}{l_t} + (1 - \\gamma^{*})s_{t - m}\\\\\n    &=& \\gamma\\frac{y_t}{l_{t - 1} + b_{t - 1}} + (1 - \\gamma)s_{t - m}\n\\end{eqnarray*}\n\\]\nLet us train a model.\n\nalpha &lt;- 0.1\nbeta &lt;- 0.1\ngamma &lt;- 0.1\n\nfit &lt;- \n  gas_consumption_ts_train |&gt; \n  model(MAM = ETS(consumption ~ error(\"M\") + trend(\"A\", alpha = alpha, beta = alpha * beta) + season(\"M\", gamma = gamma)))\n\naugment(fit)\n\n# A tsibble: 72 x 6 [1M]\n# Key:       .model [1]\n   .model year_month consumption .fitted .resid  .innov\n   &lt;chr&gt;       &lt;mth&gt;       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 MAM      2011 Jan        2006   1947.  58.8   0.0302\n 2 MAM      2011 Feb        1620   1708. -87.8  -0.0514\n 3 MAM      2011 Mar        1354   1374. -20.0  -0.0146\n 4 MAM      2011 Apr         956    917.  39.2   0.0428\n 5 MAM      2011 May         560    530.  30.0   0.0566\n 6 MAM      2011 Jun         317    304.  13.4   0.0442\n 7 MAM      2011 Jul         254    246.   7.85  0.0319\n 8 MAM      2011 Aug         214    212.   2.15  0.0102\n 9 MAM      2011 Sep         231    236.  -4.59 -0.0195\n10 MAM      2011 Oct         482    439.  43.4   0.0988\n# ℹ 62 more rows\n\n\nSee smoothing paramters.\n\ntidy(fit)\n\n# A tibble: 17 × 3\n   .model term   estimate\n   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;\n 1 MAM    alpha     0.1  \n 2 MAM    beta      0.01 \n 3 MAM    gamma     0.1  \n 4 MAM    l[0]    878.   \n 5 MAM    b[0]     -2.86 \n 6 MAM    s[0]      1.85 \n 7 MAM    s[-1]     1.06 \n 8 MAM    s[-2]     0.507\n 9 MAM    s[-3]     0.271\n10 MAM    s[-4]     0.244\n11 MAM    s[-5]     0.283\n12 MAM    s[-6]     0.350\n13 MAM    s[-7]     0.613\n14 MAM    s[-8]     1.06 \n15 MAM    s[-9]     1.58 \n16 MAM    s[-10]    1.95 \n17 MAM    s[-11]    2.23 \n\n\nSee fitness statistics.\n\nglance(fit)\n\n# A tibble: 1 × 9\n  .model  sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE    MAE\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 MAM    0.00687   -426.  879.  887.  911. 4678. 5247. 0.0604\n\n\nLet us create a forecast for 1 year (i.e. 12 months).\n\nfit |&gt; \n  forecast(h = 12)\n\n# A fable: 12 x 4 [1M]\n# Key:     .model [1]\n   .model year_month    consumption .mean\n   &lt;chr&gt;       &lt;mth&gt;         &lt;dist&gt; &lt;dbl&gt;\n 1 MAM      2017 Jan N(1763, 21338) 1763.\n 2 MAM      2017 Feb N(1553, 16753) 1553.\n 3 MAM      2017 Mar N(1261, 11215) 1261.\n 4 MAM      2017 Apr   N(838, 5032)  838.\n 5 MAM      2017 May   N(485, 1717)  485.\n 6 MAM      2017 Jun    N(280, 583)  280.\n 7 MAM      2017 Jul    N(227, 393)  227.\n 8 MAM      2017 Aug    N(195, 296)  195.\n 9 MAM      2017 Sep    N(217, 378)  217.\n10 MAM      2017 Oct   N(403, 1343)  403.\n11 MAM      2017 Nov   N(848, 6156)  848.\n12 MAM      2017 Dec N(1477, 19318) 1477.\n\n\nNow, let the training internally optimize the smoothing parameters.\n\nfit_opt &lt;- \n  gas_consumption_ts_train |&gt; \n  model(MAM = ETS(consumption ~ error(\"M\") + trend(\"A\") + season(\"M\")))\n\nCheck the optimized smoothing parameters.\n\ntidy(fit_opt)\n\n# A tibble: 17 × 3\n   .model term     estimate\n   &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;\n 1 MAM    alpha    0.0574  \n 2 MAM    beta     0.000100\n 3 MAM    gamma    0.000135\n 4 MAM    l[0]   878.      \n 5 MAM    b[0]    -1.41    \n 6 MAM    s[0]     1.86    \n 7 MAM    s[-1]    1.06    \n 8 MAM    s[-2]    0.509   \n 9 MAM    s[-3]    0.270   \n10 MAM    s[-4]    0.245   \n11 MAM    s[-5]    0.285   \n12 MAM    s[-6]    0.351   \n13 MAM    s[-7]    0.605   \n14 MAM    s[-8]    1.05    \n15 MAM    s[-9]    1.60    \n16 MAM    s[-10]   1.96    \n17 MAM    s[-11]   2.20    \n\n\nCheck the fitness statistics.\n\nglance(fit_opt)\n\n# A tibble: 1 × 9\n  .model  sigma2 log_lik   AIC  AICc   BIC   MSE  AMSE    MAE\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 MAM    0.00598   -421.  877.  888.  915. 4221. 4382. 0.0564\n\n\nAnd create forecast for next 1 year.\n\nfit_opt |&gt; \n  forecast(h = 12)\n\n# A fable: 12 x 4 [1M]\n# Key:     .model [1]\n   .model year_month    consumption .mean\n   &lt;chr&gt;       &lt;mth&gt;         &lt;dist&gt; &lt;dbl&gt;\n 1 MAM      2017 Jan N(1681, 16912) 1681.\n 2 MAM      2017 Feb N(1499, 13485) 1499.\n 3 MAM      2017 Mar  N(1220, 8961) 1220.\n 4 MAM      2017 Apr   N(800, 3864)  800.\n 5 MAM      2017 May   N(459, 1275)  459.\n 6 MAM      2017 Jun    N(266, 429)  266.\n 7 MAM      2017 Jul    N(215, 282)  215.\n 8 MAM      2017 Aug    N(185, 209)  185.\n 9 MAM      2017 Sep    N(203, 254)  203.\n10 MAM      2017 Oct    N(383, 903)  383.\n11 MAM      2017 Nov   N(792, 3878)  792.\n12 MAM      2017 Dec N(1393, 12050) 1393.\n\n\nVisualize the forecast as well as training data.\n\nfit_opt |&gt; \n  forecast(h = 12) |&gt; \n  autoplot(gas_consumption_ts_train)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.6",
    "href": "ch01_smoothing.html#example-1.6",
    "title": "1  Smoothing",
    "section": "1.5 Example 1.6",
    "text": "1.5 Example 1.6\n\n1.5.1 Load data\nLoad data from excel file, process it and convert it to be time series data frame tsibble object.\n\nelectric_consumption &lt;- \n  read_excel(\"data/J04.xlsx\", skip = 1) |&gt; \n  mutate(year = as.numeric(str_sub(`Y/Q`, 1, 4))) |&gt; \n  fill(year, .direction = \"down\") |&gt; \n  group_by(year) |&gt; \n  mutate(quarter = row_number()) |&gt; \n  ungroup() |&gt; \n  mutate(year_quarter = make_yearquarter(year, quarter)) |&gt; \n  select(year_quarter, consumption) |&gt; \n  as_tsibble(index = year_quarter)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `year = as.numeric(str_sub(`Y/Q`, 1, 4))`.\nCaused by warning:\n! NAs introduced by coercion\n\nelectric_consumption\n\n# A tsibble: 84 x 2 [1Q]\n   year_quarter consumption\n          &lt;qtr&gt;       &lt;dbl&gt;\n 1      1997 Q1        1461\n 2      1997 Q2        1406\n 3      1997 Q3        1710\n 4      1997 Q4        1514\n 5      1998 Q1        1501\n 6      1998 Q2        1426\n 7      1998 Q3        1655\n 8      1998 Q4        1540\n 9      1999 Q1        1638\n10      1999 Q2        1583\n# ℹ 74 more rows\n\n\nVisualize the series.\n\nelectric_consumption |&gt; \n  autoplot(consumption)\n\n\n\n\n\n\n\n\n\n\n1.5.2 Train/test split\n\nelectric_consumption_train &lt;- \n  electric_consumption |&gt; \n  filter(year(year_quarter) &lt;= 2015)\n\nelectric_consumption_test &lt;- \n  electric_consumption |&gt; \n  filter(year(year_quarter) &gt; 2015)\n\n\n\n1.5.3 Detrend training data\n\nm &lt;- 4\n\ndetrended &lt;-\n  electric_consumption_train |&gt; \n  mutate(\n    trend = slider::slide_mean(consumption, before = 2, after = 1, complete = TRUE),\n    trend = slider::slide_mean(trend, before = 0, after = 1, complete = TRUE),\n    detrended = consumption - trend\n  )\n\ndetrended\n\n# A tsibble: 76 x 4 [1Q]\n   year_quarter consumption trend detrended\n          &lt;qtr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1      1997 Q1        1461   NA       NA  \n 2      1997 Q2        1406   NA       NA  \n 3      1997 Q3        1710 1528.     182. \n 4      1997 Q4        1514 1535.     -21.2\n 5      1998 Q1        1501 1531.     -29.9\n 6      1998 Q2        1426 1527.    -101. \n 7      1998 Q3        1655 1548.     107. \n 8      1998 Q4        1540 1584.     -44.4\n 9      1999 Q1        1638 1628.      10.5\n10      1999 Q2        1583 1675.     -91.8\n# ℹ 66 more rows\n\n\n\n\n1.5.4 Deseasonalize data\n\nseasonality &lt;- \n  detrended |&gt; \n  as_tibble() |&gt; \n  mutate(quarter = quarter(year_quarter)) |&gt; \n  group_by(quarter) |&gt; \n  summarize(s = mean(detrended, na.rm = TRUE)) |&gt; \n  mutate(s = s - mean(s)) |&gt; \n  pull(s)\n\nseasonality\n\n[1]  353.973958 -225.630208   -5.581597 -122.762153\n\n\n\ndeseasonalized &lt;- \n  detrended |&gt; \n  mutate(\n    seasonal = seasonality[quarter(year_quarter)],\n    deseasonalized = consumption - seasonal,\n    random = consumption - trend - seasonal\n  )\n\ndeseasonalized\n\n# A tsibble: 76 x 7 [1Q]\n   year_quarter consumption trend detrended seasonal deseasonalized random\n          &lt;qtr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt;\n 1      1997 Q1        1461   NA       NA     354.            1107.   NA  \n 2      1997 Q2        1406   NA       NA    -226.            1632.   NA  \n 3      1997 Q3        1710 1528.     182.     -5.58          1716.  188. \n 4      1997 Q4        1514 1535.     -21.2  -123.            1637.  102. \n 5      1998 Q1        1501 1531.     -29.9   354.            1147. -384. \n 6      1998 Q2        1426 1527.    -101.   -226.            1652.  124. \n 7      1998 Q3        1655 1548.     107.     -5.58          1661.  113. \n 8      1998 Q4        1540 1584.     -44.4  -123.            1663.   78.4\n 9      1999 Q1        1638 1628.      10.5   354.            1284. -343. \n10      1999 Q2        1583 1675.     -91.8  -226.            1809.  134. \n# ℹ 66 more rows\n\n\n\n\n1.5.5 Use feasts::classical_decomposition()\nclassical_decomposition() from {feasts} package is a short cut to decompose a series into trend, seasonality and random components. Find additional explanation from Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos.\nFirst, call classical_decomposition() inside model() function. The model() function returns mable object, which stands for “model table”. To use the additive model, pass type = \"additive\" argument inside classical_decomposition().\n\nelectric_consumption_additive &lt;- \n  electric_consumption_train |&gt; \n  model(classical_decomposition(consumption, type = \"additive\"))\n\nelectric_consumption_additive\n\n# A mable: 1 x 1\n  `classical_decomposition(consumption, type = \"additive\")`\n                                                    &lt;model&gt;\n1                                           &lt;DECOMPOSITION&gt;\n\n\nTo see series of each component, call components(). This function returns dable object, which stands for “decomposition table”.\ntrend, seasonal, and random columns represent trend, seasonality, and random component, respectively. season_adjust represents the deseasonalized series.\n\nelectric_consumption_additive |&gt; \n  components()\n\n# A dable: 76 x 7 [1Q]\n# Key:     .model [1]\n# :        consumption = trend + seasonal + random\n   .model           year_quarter consumption trend seasonal random season_adjust\n   &lt;chr&gt;                   &lt;qtr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n 1 \"classical_deco…      1997 Q1        1461   NA    354.     NA           1107.\n 2 \"classical_deco…      1997 Q2        1406   NA   -226.     NA           1632.\n 3 \"classical_deco…      1997 Q3        1710 1528.    -5.58  188.          1716.\n 4 \"classical_deco…      1997 Q4        1514 1535.  -123.    102.          1637.\n 5 \"classical_deco…      1998 Q1        1501 1531.   354.   -384.          1147.\n 6 \"classical_deco…      1998 Q2        1426 1527.  -226.    124.          1652.\n 7 \"classical_deco…      1998 Q3        1655 1548.    -5.58  113.          1661.\n 8 \"classical_deco…      1998 Q4        1540 1584.  -123.     78.4         1663.\n 9 \"classical_deco…      1999 Q1        1638 1628.   354.   -343.          1284.\n10 \"classical_deco…      1999 Q2        1583 1675.  -226.    134.          1809.\n# ℹ 66 more rows\n\n\nVisualize the components.\n\nelectric_consumption_additive |&gt; \n  components() |&gt; \n  autoplot()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n1.5.6 Forecast\nUse the deseasonalized series to produce a forecast.\n\nfit_poly &lt;- \n  deseasonalized |&gt; \n  mutate(t = row_number()) |&gt; \n  lm(deseasonalized ~ t + I(t^2), data = _)\n\nbroom::tidy(fit_poly)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept) 1098.      53.7         20.4 6.33e-32\n2 t             72.2      3.22        22.4 1.81e-34\n3 I(t^2)        -0.431    0.0405     -10.6 1.72e-16\n\n\nCreate forecast for two years.\n\nelectric_consumption_test &lt;- \n  electric_consumption_test |&gt; \n  mutate(t = nrow(electric_consumption_train) + row_number())\n  \nelectric_consumption_test |&gt; \n  mutate(\n    trend = predict(fit_poly, newdata = electric_consumption_test),\n    seasonality = seasonality[quarter(year_quarter)],\n    forecast = trend + seasonality,\n    forecast_error = consumption - forecast\n  )\n\n# A tsibble: 8 x 7 [1Q]\n  year_quarter consumption     t trend seasonality forecast forecast_error\n         &lt;qtr&gt;       &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1      2016 Q1        4610    77 4101.      354.      4455.          155. \n2      2016 Q2        3734    78 4106.     -226.      3880.         -146. \n3      2016 Q3        4365    79 4111.       -5.58    4105.          260. \n4      2016 Q4        3943    80 4114.     -123.      3992.          -48.5\n5      2017 Q1        4611    81 4117.      354.      4471.          140. \n6      2017 Q2        3789    82 4119.     -226.      3893.         -104. \n7      2017 Q3        4448    83 4120.       -5.58    4115.          333. \n8      2017 Q4        4088    84 4120.     -123.      3998.           90.4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.7",
    "href": "ch01_smoothing.html#example-1.7",
    "title": "1  Smoothing",
    "section": "1.6 Example 1.7",
    "text": "1.6 Example 1.7\n\n1.6.1 Load data\nUse the same data to previous example.\n\nelectric_consumption &lt;- \n  read_excel(\"data/J04.xlsx\", skip = 1) |&gt; \n  mutate(year = as.numeric(str_sub(`Y/Q`, 1, 4))) |&gt; \n  fill(year, .direction = \"down\") |&gt; \n  group_by(year) |&gt; \n  mutate(quarter = row_number()) |&gt; \n  ungroup() |&gt; \n  mutate(year_quarter = make_yearquarter(year, quarter)) |&gt; \n  select(year_quarter, consumption) |&gt; \n  as_tsibble(index = year_quarter)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `year = as.numeric(str_sub(`Y/Q`, 1, 4))`.\nCaused by warning:\n! NAs introduced by coercion\n\nelectric_consumption_train &lt;- \n  electric_consumption |&gt; \n  filter(year(year_quarter) &lt;= 2015)\n\nelectric_consumption_test &lt;- \n  electric_consumption |&gt; \n  filter(year(year_quarter) &gt; 2015)\n\n\n\n1.6.2 Detrend training data\n\nm &lt;- 4\n\ndetrended &lt;-\n  electric_consumption_train |&gt; \n  mutate(\n    trend = slider::slide_mean(consumption, before = 2, after = 1, complete = TRUE),\n    trend = slider::slide_mean(trend, before = 0, after = 1, complete = TRUE),\n    detrended = consumption / trend\n  )\n\ndetrended\n\n# A tsibble: 76 x 4 [1Q]\n   year_quarter consumption trend detrended\n          &lt;qtr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1      1997 Q1        1461   NA     NA    \n 2      1997 Q2        1406   NA     NA    \n 3      1997 Q3        1710 1528.     1.12 \n 4      1997 Q4        1514 1535.     0.986\n 5      1998 Q1        1501 1531.     0.980\n 6      1998 Q2        1426 1527.     0.934\n 7      1998 Q3        1655 1548.     1.07 \n 8      1998 Q4        1540 1584.     0.972\n 9      1999 Q1        1638 1628.     1.01 \n10      1999 Q2        1583 1675.     0.945\n# ℹ 66 more rows\n\n\n\n\n1.6.3 Deseasonalize data\n\nseasonality &lt;- \n  detrended |&gt; \n  as_tibble() |&gt; \n  mutate(quarter = quarter(year_quarter)) |&gt; \n  group_by(quarter) |&gt; \n  summarize(s = mean(detrended, na.rm = TRUE)) |&gt; \n  mutate(s = s / mean(s)) |&gt; \n  pull(s)\n\nseasonality\n\n[1] 1.1035624 0.9291657 1.0067075 0.9605644\n\n\n\ndeseasonalized &lt;- \n  detrended |&gt; \n  mutate(\n    seasonal = seasonality[quarter(year_quarter)],\n    deseasonalized = consumption / seasonal,\n    random = consumption / (trend * seasonal)\n  )\n\ndeseasonalized\n\n# A tsibble: 76 x 7 [1Q]\n   year_quarter consumption trend detrended seasonal deseasonalized random\n          &lt;qtr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt;\n 1      1997 Q1        1461   NA     NA        1.10           1324. NA    \n 2      1997 Q2        1406   NA     NA        0.929          1513. NA    \n 3      1997 Q3        1710 1528.     1.12     1.01           1699.  1.11 \n 4      1997 Q4        1514 1535.     0.986    0.961          1576.  1.03 \n 5      1998 Q1        1501 1531.     0.980    1.10           1360.  0.888\n 6      1998 Q2        1426 1527.     0.934    0.929          1535.  1.00 \n 7      1998 Q3        1655 1548.     1.07     1.01           1644.  1.06 \n 8      1998 Q4        1540 1584.     0.972    0.961          1603.  1.01 \n 9      1999 Q1        1638 1628.     1.01     1.10           1484.  0.912\n10      1999 Q2        1583 1675.     0.945    0.929          1704.  1.02 \n# ℹ 66 more rows\n\n\n\n\n1.6.4 Use feasts::classical_decomposition()\nCall classical_decomposition() with type = \"multiplicative\" argument.\n\nelectric_consumption_multiplicative &lt;- \n  electric_consumption_train |&gt; \n  model(classical_decomposition(consumption, type = \"multiplicative\"))\n\n\nelectric_consumption_multiplicative |&gt; \n  components()\n\n# A dable: 76 x 7 [1Q]\n# Key:     .model [1]\n# :        consumption = trend * seasonal * random\n   .model           year_quarter consumption trend seasonal random season_adjust\n   &lt;chr&gt;                   &lt;qtr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n 1 \"classical_deco…      1997 Q1        1461   NA     1.10  NA             1324.\n 2 \"classical_deco…      1997 Q2        1406   NA     0.929 NA             1513.\n 3 \"classical_deco…      1997 Q3        1710 1528.    1.01   1.11          1699.\n 4 \"classical_deco…      1997 Q4        1514 1535.    0.961  1.03          1576.\n 5 \"classical_deco…      1998 Q1        1501 1531.    1.10   0.888         1360.\n 6 \"classical_deco…      1998 Q2        1426 1527.    0.929  1.00          1535.\n 7 \"classical_deco…      1998 Q3        1655 1548.    1.01   1.06          1644.\n 8 \"classical_deco…      1998 Q4        1540 1584.    0.961  1.01          1603.\n 9 \"classical_deco…      1999 Q1        1638 1628.    1.10   0.912         1484.\n10 \"classical_deco…      1999 Q2        1583 1675.    0.929  1.02          1704.\n# ℹ 66 more rows\n\n\n\nelectric_consumption_multiplicative |&gt; \n  components() |&gt; \n  autoplot()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n1.6.5 Forecast\n\nfit_poly &lt;- \n  deseasonalized |&gt; \n  mutate(t = row_number()) |&gt; \n  lm(deseasonalized ~ t + I(t^2), data = _)\n\nbroom::tidy(fit_poly)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept) 1116.      41.6         26.8 1.57e-39\n2 t             71.2      2.49        28.5 2.45e-41\n3 I(t^2)        -0.421    0.0314     -13.4 2.34e-21\n\n\nCreate forecast for two years.\n\nelectric_consumption_test &lt;- \n  electric_consumption_test |&gt; \n  mutate(t = nrow(electric_consumption_train) + row_number())\n  \nelectric_consumption_test |&gt; \n  mutate(\n    trend = predict(fit_poly, newdata = electric_consumption_test),\n    seasonality = seasonality[quarter(year_quarter)],\n    forecast = trend * seasonality,\n    forecast_error = consumption - forecast\n  )\n\n# A tsibble: 8 x 7 [1Q]\n  year_quarter consumption     t trend seasonality forecast forecast_error\n         &lt;qtr&gt;       &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1      2016 Q1        4610    77 4104.       1.10     4529.           80.8\n2      2016 Q2        3734    78 4110.       0.929    3819.          -85.0\n3      2016 Q3        4365    79 4115.       1.01     4143.          222. \n4      2016 Q4        3943    80 4120.       0.961    3957.          -14.2\n5      2017 Q1        4611    81 4123.       1.10     4550.           60.9\n6      2017 Q2        3789    82 4126.       0.929    3834.          -44.5\n7      2017 Q3        4448    83 4128.       1.01     4155.          293. \n8      2017 Q4        4088    84 4129.       0.961    3966.          122.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.8",
    "href": "ch01_smoothing.html#example-1.8",
    "title": "1  Smoothing",
    "section": "1.7 Example 1.8",
    "text": "1.7 Example 1.8\n{fabletools} package that is automatically loaded along with {fable} provides forecast accuracy evaluation functions.\nLet us evaluate 1-year forecast accuracy from Example 1.5. (Book example evaluated for 2 years, but here we will see only 1-year forecast.)\n\nMSE(gas_consumption_winters_forecast$forecast_error)\n\n[1] 14585.48\n\nRMSE(gas_consumption_winters_forecast$forecast_error)\n\n[1] 120.7704\n\nMAE(gas_consumption_winters_forecast$forecast_error)\n\n[1] 71.72264\n\nMAPE(gas_consumption_winters_forecast$forecast_error, gas_consumption_winters_forecast$consumption)\n\n[1] 7.033255",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch01_smoothing.html#example-1.9",
    "href": "ch01_smoothing.html#example-1.9",
    "title": "1  Smoothing",
    "section": "1.8 Example 1.9",
    "text": "1.8 Example 1.9\n\n1.8.1 Load data\n\npatent_ts &lt;- \n  read_excel(\"data/J02.xlsx\") |&gt; \n  rename(cnt = `#patents`) |&gt; \n  as_tsibble(index = year)\n\n\n\n1.8.2 Time series cross-validation\nTo create one-step forecast in historical data, you need to set up time series cross-validation. Great explanation is provided in Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos.\nCall stretch_tsibble() to construct time series cross-validation that each training set is defined by .id, which is used as a key in the output tsibble object. Apply filter(.id != max(.id)) to exclude the last set that entire data is used as training data.\n\npatent_cv &lt;- \n  patent_ts |&gt; \n  stretch_tsibble(.step = 1, .init = 7) |&gt; \n  filter(.id != max(.id))\n\npatent_cv\n\n# A tsibble: 255 x 3 [1Y]\n# Key:       .id [17]\n    year   cnt   .id\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n 1  1993  21.5     1\n 2  1994  28.6     1\n 3  1995  59.2     1\n 4  1996  68.4     1\n 5  1997  67.3     1\n 6  1998  50.6     1\n 7  1999  56       1\n 8  1993  21.5     2\n 9  1994  28.6     2\n10  1995  59.2     2\n# ℹ 245 more rows\n\n\n\n\n1.8.3 Models\nLet us use Holt’s linear method with optimized initialization and smoothing parameters. As a result, it will return one model object per each cross-validation set.\n\nfit_cv &lt;- \n  patent_cv |&gt; \n  model(\n    Holt = ETS(cnt ~ error(\"A\") + trend(\"A\") + season(\"N\"))\n  )\n\nfit_cv\n\n# A mable: 17 x 2\n# Key:     .id [17]\n     .id         Holt\n   &lt;int&gt;      &lt;model&gt;\n 1     1 &lt;ETS(A,A,N)&gt;\n 2     2 &lt;ETS(A,A,N)&gt;\n 3     3 &lt;ETS(A,A,N)&gt;\n 4     4 &lt;ETS(A,A,N)&gt;\n 5     5 &lt;ETS(A,A,N)&gt;\n 6     6 &lt;ETS(A,A,N)&gt;\n 7     7 &lt;ETS(A,A,N)&gt;\n 8     8 &lt;ETS(A,A,N)&gt;\n 9     9 &lt;ETS(A,A,N)&gt;\n10    10 &lt;ETS(A,A,N)&gt;\n11    11 &lt;ETS(A,A,N)&gt;\n12    12 &lt;ETS(A,A,N)&gt;\n13    13 &lt;ETS(A,A,N)&gt;\n14    14 &lt;ETS(A,A,N)&gt;\n15    15 &lt;ETS(A,A,N)&gt;\n16    16 &lt;ETS(A,A,N)&gt;\n17    17 &lt;ETS(A,A,N)&gt;\n\n\n\n\n1.8.4 Forecast\nCall forecast(h = 1) to produce one-step forecast for each model in the mable object. As a result, it returns a fable object, forecast table, that each row represents each cross validation set and column .mean represents the point forecast.\n\nfc_cv &lt;- \n  fit_cv |&gt; \n  forecast(h = 1)\n\nfc_cv\n\n# A fable: 17 x 5 [1Y]\n# Key:     .id, .model [17]\n     .id .model  year         cnt .mean\n   &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;      &lt;dist&gt; &lt;dbl&gt;\n 1     1 Holt    2000  N(72, 388)  72.4\n 2     2 Holt    2001  N(78, 291)  78.0\n 3     3 Holt    2002  N(82, 235)  81.6\n 4     4 Holt    2003  N(85, 199)  84.8\n 5     5 Holt    2004  N(91, 174)  91.4\n 6     6 Holt    2005 N(100, 172)  99.9\n 7     7 Holt    2006 N(110, 198) 110. \n 8     8 Holt    2007 N(133, 169) 133. \n 9     9 Holt    2008 N(136, 160) 136. \n10    10 Holt    2009 N(135, 139) 135. \n11    11 Holt    2010 N(135, 133) 135. \n12    12 Holt    2011 N(139, 125) 139. \n13    13 Holt    2012 N(146, 117) 146. \n14    14 Holt    2013 N(156, 109) 156. \n15    15 Holt    2014 N(168, 104) 168. \n16    16 Holt    2015  N(172, 99) 172. \n17    17 Holt    2016  N(175, 94) 175. \n\n\n\n\n1.8.5 Evaluation\nFinally, evaluate accuracy by calling accuracy() function. It returns a data frame that a row represents a model and columns represent metrics.\n\nfc_cv |&gt; \n  accuracy(patent_ts, measures = list(MSE = MSE, RMSE = RMSE, MAE = MAE, MAPE = MAPE))\n\n# A tibble: 1 × 6\n  .model .type   MSE  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Holt   Test   79.9  8.94  6.95  5.80\n\n\nThe performance is better than the book example, because of optimal smoothing paramters and initialization.\n\n\n1.8.6 Multiple models\nYou can compare multiple models by adding more models in model().\n\nfit_cv &lt;- \n  patent_cv |&gt; \n  model(\n    Holt = ETS(cnt ~ error(\"A\") + trend(\"A\") + season(\"N\")),\n    Mean = MEAN(cnt),\n    Naive = NAIVE(cnt),\n    lm = TSLM(cnt ~ trend()),\n    theta = THETA(cnt, method = \"additive\")\n  )\n\nfit_cv\n\n# A mable: 17 x 6\n# Key:     .id [17]\n     .id         Holt    Mean   Naive      lm   theta\n   &lt;int&gt;      &lt;model&gt; &lt;model&gt; &lt;model&gt; &lt;model&gt; &lt;model&gt;\n 1     1 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 2     2 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 3     3 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 4     4 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 5     5 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 6     6 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 7     7 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 8     8 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n 9     9 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n10    10 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n11    11 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n12    12 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n13    13 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n14    14 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n15    15 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n16    16 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n17    17 &lt;ETS(A,A,N)&gt;  &lt;MEAN&gt; &lt;NAIVE&gt;  &lt;TSLM&gt; &lt;THETA&gt;\n\n\nNow, each combination of cross-validation set and forecast model shows one-step forecast.\n\nfc_cv &lt;- \n  fit_cv |&gt; \n  forecast(h = 1)\n\nfc_cv\n\n# A fable: 85 x 5 [1Y]\n# Key:     .id, .model [85]\n     .id .model  year        cnt .mean\n   &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;     &lt;dist&gt; &lt;dbl&gt;\n 1     1 Holt    2000 N(72, 388)  72.4\n 2     1 Mean    2000 N(50, 386)  50.2\n 3     1 Naive   2000 N(56, 230)  56  \n 4     1 lm      2000 N(72, 399)  72.5\n 5     1 theta   2000 N(59, 276)  58.8\n 6     2 Holt    2001 N(78, 291)  78.0\n 7     2 Mean    2001 N(53, 398)  53.0\n 8     2 Naive   2001 N(73, 238)  72.8\n 9     2 lm      2001 N(78, 312)  78.2\n10     2 theta   2001 N(76, 277)  75.6\n# ℹ 75 more rows\n\n\nAnd you can compare models based on forecast accuracy metrics.\n\nfc_cv |&gt; \n  accuracy(patent_ts, measures = list(MSE = MSE, RMSE = RMSE, MAE = MAE, MAPE = MAPE))\n\n# A tibble: 5 × 6\n  .model .type    MSE  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Holt   Test    79.9  8.94  6.95  5.80\n2 Mean   Test  2729.  52.2  49.7  38.9 \n3 Naive  Test    79.9  8.94  6.96  6.28\n4 lm     Test    77.4  8.80  7.12  5.93\n5 theta  Test    52.8  7.27  5.31  4.86",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Smoothing</span>"
    ]
  },
  {
    "objectID": "ch02_stationary.html",
    "href": "ch02_stationary.html",
    "title": "2  Stationary time series",
    "section": "",
    "text": "2.1 Examples 2.2, 2.4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stationary time series</span>"
    ]
  },
  {
    "objectID": "ch02_stationary.html#examples-2.2-2.4",
    "href": "ch02_stationary.html#examples-2.2-2.4",
    "title": "2  Stationary time series",
    "section": "",
    "text": "2.1.1 Load data\n\nearthquake &lt;-\n  read_excel(\"data/J08.xlsx\", skip = 1, n_max = 50) |&gt;\n  mutate(year = year(year)) |&gt;\n  as_tsibble(index = year)\nearthquake\n\n# A tsibble: 50 x 2 [1Y]\n    year numbers\n   &lt;dbl&gt;   &lt;dbl&gt;\n 1  1949      36\n 2  1950      39\n 3  1951      21\n 4  1952      17\n 5  1953      22\n 6  1954      17\n 7  1955      19\n 8  1956      15\n 9  1957      34\n10  1958      10\n# ℹ 40 more rows\n\n\n\n\n2.1.2 Sample mean and sample variance\nSample size:\n\nn &lt;- nrow(earthquake)\n\nSample mean:\n\nz_bar &lt;- mean(earthquake$numbers)\nz_bar\n\n[1] 18.5\n\n\nSample variance:\n\ngamma_0 &lt;- var(earthquake$numbers)\ngamma_0\n\n[1] 49.96939\n\n\n\n\n2.1.3 Ex 2.2: Autocorrelation function\nUse n - 1 as denominator for covariance.\n\nrho &lt;- map_dbl(\n  1:10,\n  \\(k) sum((earthquake$numbers[(k+1):n] - z_bar) * \n           (earthquake$numbers[1:(n-k)] - z_bar)) / \n           (n - 1) / gamma_0\n)\nrho\n\n [1]  0.39503778  0.31141515  0.26536655  0.21952216  0.15141924  0.08045742\n [7]  0.15754544  0.07392281 -0.10200123 -0.09250562\n\n\n\n2.1.3.1 Use stats::acf()\n{stats}, one of R’s core package, provides acf() function to compute autocorrelation.\n\nacf_results &lt;- acf(earthquake$numbers, type = \"correlation\", plot = FALSE, lag.max = 10)\nacf_results\n\n\nAutocorrelations of series 'earthquake$numbers', by lag\n\n     0      1      2      3      4      5      6      7      8      9     10 \n 1.000  0.395  0.311  0.265  0.220  0.151  0.080  0.158  0.074 -0.102 -0.093 \n\n\n\n\n2.1.3.2 Use feasts::ACF()\n{feasts}, a part of tidyverts framework, provide ACF() function to compute autocorrelation on tsibble object.\n\nearthquake |&gt; \n  ACF(numbers, lag_max = 10)\n\n# A tsibble: 10 x 2 [1Y]\n        lag     acf\n   &lt;cf_lag&gt;   &lt;dbl&gt;\n 1       1Y  0.395 \n 2       2Y  0.311 \n 3       3Y  0.265 \n 4       4Y  0.220 \n 5       5Y  0.151 \n 6       6Y  0.0805\n 7       7Y  0.158 \n 8       8Y  0.0739\n 9       9Y -0.102 \n10      10Y -0.0925\n\n\nVisualize autocorrelation function.\n\nearthquake |&gt; \n  ACF(numbers, lag_max = 10) |&gt; \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n2.1.4 Ex 2.4: Partial autocorrelation function\n\nx &lt;- c(acf_results$acf[10:2], acf_results$acf[1:10])\ny &lt;- acf_results$acf[2:11]\n\nmat &lt;- reduce(\n  2:10,\n  \\(m, i) rbind(m, x[(10 - i) + (1:10)]),\n  .init = x[10:19]\n)\n\nmap_dbl(\n  1:10,\n  \\(k) solve(mat[1:k, 1:k], y[1:k])[k]\n)\n\n [1]  0.395037778  0.184088155  0.113167641  0.060683539 -0.004447767\n [6] -0.046903292  0.109748706 -0.035820889 -0.209890421 -0.061031590\n\n\n\n2.1.4.1 Use stats::pacf()\n\npacf(earthquake$numbers, lag.max = 10, plot = FALSE)\n\n\nPartial autocorrelations of series 'earthquake$numbers', by lag\n\n     1      2      3      4      5      6      7      8      9     10 \n 0.395  0.184  0.113  0.061 -0.004 -0.047  0.110 -0.036 -0.210 -0.061 \n\n\n\n\n2.1.4.2 Use feasts::PACF()\n\nearthquake |&gt; \n  PACF(numbers, lag_max = 10)\n\n# A tsibble: 10 x 2 [1Y]\n        lag     pacf\n   &lt;cf_lag&gt;    &lt;dbl&gt;\n 1       1Y  0.395  \n 2       2Y  0.184  \n 3       3Y  0.113  \n 4       4Y  0.0607 \n 5       5Y -0.00445\n 6       6Y -0.0469 \n 7       7Y  0.110  \n 8       8Y -0.0358 \n 9       9Y -0.210  \n10      10Y -0.0610 \n\n\nVisualize partial autocorrelation function.\n\nearthquake |&gt; \n  PACF(numbers, lag_max = 10)\n\n# A tsibble: 10 x 2 [1Y]\n        lag     pacf\n   &lt;cf_lag&gt;    &lt;dbl&gt;\n 1       1Y  0.395  \n 2       2Y  0.184  \n 3       3Y  0.113  \n 4       4Y  0.0607 \n 5       5Y -0.00445\n 6       6Y -0.0469 \n 7       7Y  0.110  \n 8       8Y -0.0358 \n 9       9Y -0.210  \n10      10Y -0.0610",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Stationary time series</span>"
    ]
  },
  {
    "objectID": "ch04_arma_estimation.html",
    "href": "ch04_arma_estimation.html",
    "title": "4  ARMA identification and estimation",
    "section": "",
    "text": "4.1 Example 4.1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ARMA identification and estimation</span>"
    ]
  },
  {
    "objectID": "ch04_arma_estimation.html#example-4.1",
    "href": "ch04_arma_estimation.html#example-4.1",
    "title": "4  ARMA identification and estimation",
    "section": "",
    "text": "4.1.1 Data\n\nts &lt;- \n  tsibble(\n    t = 1:15,\n    value = c(-1.01, -0.81, -0.33, -0.40, -0.95, -1.33, 0.72, 0.63,\n               1.30, 1.08, -0.33, 0.31, 0.10, -0.41, -0.22),\n    index = t\n  )\n\n\n\n4.1.2 ACF\n\nts |&gt; \n  ACF(value)\n\n# A tsibble: 11 x 2 [1]\n        lag      acf\n   &lt;cf_lag&gt;    &lt;dbl&gt;\n 1        1  0.480  \n 2        2  0.160  \n 3        3  0.0257 \n 4        4 -0.154  \n 5        5 -0.0968 \n 6        6 -0.284  \n 7        7 -0.323  \n 8        8 -0.240  \n 9        9 -0.0792 \n10       10  0.00431\n11       11 -0.0494 \n\n\n\n\n4.1.3 PACF\n\nts |&gt; \n  PACF(value)\n\n# A tsibble: 11 x 2 [1]\n        lag    pacf\n   &lt;cf_lag&gt;   &lt;dbl&gt;\n 1        1  0.480 \n 2        2 -0.0906\n 3        3 -0.0193\n 4        4 -0.190 \n 5        5  0.0871\n 6        6 -0.348 \n 7        7 -0.0503\n 8        8 -0.116 \n 9        9  0.156 \n10       10 -0.171 \n11       11 -0.0454",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ARMA identification and estimation</span>"
    ]
  },
  {
    "objectID": "ch04_arma_estimation.html#examples-4.2-4.7---4.8",
    "href": "ch04_arma_estimation.html#examples-4.2-4.7---4.8",
    "title": "4  ARMA identification and estimation",
    "section": "4.2 Examples 4.2, 4.7 - 4.8",
    "text": "4.2 Examples 4.2, 4.7 - 4.8\n\n4.2.1 Load data\n\nnile_flow &lt;- read_excel(\n  \"data/J09.xlsx\", \n  n_max = 99, \n  .name_repair = janitor::make_clean_names\n) |&gt; \n  mutate(year = 1872:1970) |&gt; \n  as_tsibble(index = year)\n\nWarning: Expecting numeric in A30 / R30C1: got a date\n\n\nWarning: Expecting numeric in A31 / R31C1: got a date\n\n\nWarning: Expecting numeric in A32 / R32C1: got a date\n\n\nWarning: Expecting numeric in A33 / R33C1: got a date\n\n\nWarning: Expecting numeric in A34 / R34C1: got a date\n\n\nWarning: Expecting numeric in A35 / R35C1: got a date\n\n\nWarning: Expecting numeric in A36 / R36C1: got a date\n\n\nWarning: Expecting numeric in A37 / R37C1: got a date\n\n\nWarning: Expecting numeric in A38 / R38C1: got a date\n\n\nWarning: Expecting numeric in A39 / R39C1: got a date\n\n\nWarning: Expecting numeric in A40 / R40C1: got a date\n\n\nWarning: Expecting numeric in A41 / R41C1: got a date\n\n\nWarning: Expecting numeric in A42 / R42C1: got a date\n\n\nWarning: Expecting numeric in A43 / R43C1: got a date\n\n\nWarning: Expecting numeric in A44 / R44C1: got a date\n\n\nWarning: Expecting numeric in A45 / R45C1: got a date\n\n\nWarning: Expecting numeric in A46 / R46C1: got a date\n\n\nWarning: Expecting numeric in A47 / R47C1: got a date\n\n\nWarning: Expecting numeric in A48 / R48C1: got a date\n\n\nWarning: Expecting numeric in A49 / R49C1: got a date\n\n\nWarning: Expecting numeric in A50 / R50C1: got a date\n\n\nWarning: Expecting numeric in A51 / R51C1: got a date\n\n\nWarning: Expecting numeric in A52 / R52C1: got a date\n\n\nWarning: Expecting numeric in A53 / R53C1: got a date\n\n\nWarning: Expecting numeric in A54 / R54C1: got a date\n\n\nWarning: Expecting numeric in A55 / R55C1: got a date\n\n\nWarning: Expecting numeric in A56 / R56C1: got a date\n\n\nWarning: Expecting numeric in A57 / R57C1: got a date\n\n\nWarning: Expecting numeric in A58 / R58C1: got a date\n\n\nWarning: Expecting numeric in A59 / R59C1: got a date\n\n\nWarning: Expecting numeric in A60 / R60C1: got a date\n\n\nWarning: Expecting numeric in A61 / R61C1: got a date\n\n\nWarning: Expecting numeric in A62 / R62C1: got a date\n\n\nWarning: Expecting numeric in A63 / R63C1: got a date\n\n\nWarning: Expecting numeric in A64 / R64C1: got a date\n\n\nWarning: Expecting numeric in A65 / R65C1: got a date\n\n\nWarning: Expecting numeric in A66 / R66C1: got a date\n\n\nWarning: Expecting numeric in A67 / R67C1: got a date\n\n\nWarning: Expecting numeric in A68 / R68C1: got a date\n\n\nWarning: Expecting numeric in A69 / R69C1: got a date\n\n\nWarning: Expecting numeric in A70 / R70C1: got a date\n\n\nWarning: Expecting numeric in A71 / R71C1: got a date\n\n\nWarning: Expecting numeric in A72 / R72C1: got a date\n\n\nWarning: Expecting numeric in A73 / R73C1: got a date\n\n\nWarning: Expecting numeric in A74 / R74C1: got a date\n\n\nWarning: Expecting numeric in A75 / R75C1: got a date\n\n\nWarning: Expecting numeric in A76 / R76C1: got a date\n\n\nWarning: Expecting numeric in A77 / R77C1: got a date\n\n\nWarning: Expecting numeric in A78 / R78C1: got a date\n\n\nWarning: Expecting numeric in A79 / R79C1: got a date\n\n\nWarning: Expecting numeric in A80 / R80C1: got a date\n\n\nWarning: Expecting numeric in A81 / R81C1: got a date\n\n\nWarning: Expecting numeric in A82 / R82C1: got a date\n\n\nWarning: Expecting numeric in A83 / R83C1: got a date\n\n\nWarning: Expecting numeric in A84 / R84C1: got a date\n\n\nWarning: Expecting numeric in A85 / R85C1: got a date\n\n\nWarning: Expecting numeric in A86 / R86C1: got a date\n\n\nWarning: Expecting numeric in A87 / R87C1: got a date\n\n\nWarning: Expecting numeric in A88 / R88C1: got a date\n\n\nWarning: Expecting numeric in A89 / R89C1: got a date\n\n\nWarning: Expecting numeric in A90 / R90C1: got a date\n\n\nWarning: Expecting numeric in A91 / R91C1: got a date\n\n\nWarning: Expecting numeric in A92 / R92C1: got a date\n\n\nWarning: Expecting numeric in A93 / R93C1: got a date\n\n\nWarning: Expecting numeric in A94 / R94C1: got a date\n\n\nWarning: Expecting numeric in A95 / R95C1: got a date\n\n\nWarning: Expecting numeric in A96 / R96C1: got a date\n\n\nWarning: Expecting numeric in A97 / R97C1: got a date\n\n\nWarning: Expecting numeric in A98 / R98C1: got a date\n\n\nWarning: Expecting numeric in A99 / R99C1: got a date\n\n\nWarning: Expecting numeric in A100 / R100C1: got a date\n\n\n\nnile_flow |&gt; \n  autoplot(mean_flow)\n\n\n\n\n\n\n\n\n\n\n4.2.2 Ex 4.2: Model identification\n\n4.2.2.1 ACF\n\nnile_flow |&gt; \n  ACF(mean_flow) |&gt; \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n4.2.2.2 PACF\n\nnile_flow |&gt; \n  PACF(mean_flow) |&gt; \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n4.2.3 Ex 4.7: Model estimation\nUse AR() from {fable} package. In formula, use order(2) set the order of auto-regressive term to be 2.\n\nar_fit &lt;- \n  nile_flow |&gt; \n  model(AR = AR(mean_flow ~ order(2)))\n\nar_fit\n\n# A mable: 1 x 1\n               AR\n          &lt;model&gt;\n1 &lt;AR(2) w/ mean&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse order() without argument if you want to let the order of auto-regressive term to be optimized based on information criterion.\n\n\nSee the estimated model.\n\nreport(ar_fit)\n\nSeries: mean_flow \nModel: AR(2) w/ mean \n\nCoefficients:\n  constant     ar1     ar2\n  360.5505  0.4011  0.2021\n\nsigma^2 estimated as 20322\nAIC = -27.53    AICc = -27.28   BIC = -19.75\n\n\nSee more detailed statistics of the regression coefficients.\n\ntidy(ar_fit)\n\n# A tibble: 3 × 6\n  .model term     estimate std.error statistic  p.value\n  &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 AR     constant  361.      93.3         3.86 0.000202\n2 AR     ar1         0.401    0.0994      4.03 0.000110\n3 AR     ar2         0.202    0.0991      2.04 0.0443  \n\n\nSee model-level statistics.\n\nglance(ar_fit)\n\n# A tibble: 1 × 6\n  .model sigma2   AIC  AICc   BIC   dof\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 AR     20322. -27.5 -27.3 -19.7    96\n\n\n\n\n4.2.4 Ex 4.8: Residual diagnostics\n\nar_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box, lag = 12)\n\n# A tibble: 1 × 3\n  .model lb_stat lb_pvalue\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 AR        11.5     0.488",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ARMA identification and estimation</span>"
    ]
  }
]