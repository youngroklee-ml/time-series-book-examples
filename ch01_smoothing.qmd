# Smoothing

```{r}
library(tidyverse)
library(tsibble) # time series data frame wrangling
library(fable)   # forecasting models
library(feasts)  # feature extraction, statistics, visualization for time series data
library(readxl)
```

## Example 1.1

### Data

Create a data frame.

```{r}
forest_fire <- tribble(
  ~year, ~cnt,
  2006, 369,
  2007, 418,
  2008, 389,
  2009, 570,
  2010, 282,
  2011, 277,
  2012, 197,
  2013, 296,
  2014, 492,
  2015, 623,
  2016, 391
)
```

### Convert to time-series data

Convert the data frame to time series data frame (`tsibble`) object. You must set `index` with a column that represents timepoints for the series. Please note that `tsibble` automatically notice that the index is year and that the series is regular yearly series.

```{r}
forest_fire_ts <-
  forest_fire |>
  as_tsibble(index = year)

forest_fire_ts
```


### Moving average

Compute moving average by calling `slider::slide_mean()`. Set `complete = TRUE` to return missing value `NA` when there are missing observations in the sliding window.

```{r}
forest_fire_ma <-
  forest_fire_ts |>
  mutate(
    ma3 = slider::slide_mean(cnt, before = 2, after = 0, complete = TRUE),
    ma6 = slider::slide_mean(cnt, before = 5, after = 0, complete = TRUE)
  )

forest_fire_ma
```


:::{.callout-note}
`{slider}` package provides functions to conduct rolling analysis using window functions. `slide_*()` function family is useful for time series with regular observations (i.e. no missing time period) as in this example. If your time series appear to be irregular, `slide_index_*()` function family would be useful.
:::

Now, `forest_fire_ma` is a time series data frame with three series: original value `cnt`, 3-yr moving average `ma3`, and 6-yr moving average `ma6`. 


### Visualization

Covert this to a long form by calling `pivot_longer()`. The resulting time series data frame will have `key` that is a label of each series.

```{r}
forest_fire_ma_long <- 
  forest_fire_ma |>
  pivot_longer(c(cnt, ma3, ma6), names_to = "statistics")

forest_fire_ma_long
```


Visualize time series data. Call `autoplot()` with measurement variable name to draws line plot by each `key`.

```{r}
forest_fire_ma_long |> 
  autoplot(value)
```


## Example 1.2

### Load data

```{r}
household <- 
  read_excel("data/J01.xlsx", skip = 1) |> 
  rename(cnt = `#households`)
```

### Convert to time-series data

```{r}
household_ts <-
  household |> 
  as_tsibble(index = year)

household_ts
```


### Train/test split

```{r}
household_ts_train <-
  household_ts |> 
  filter(year <= 2014)

household_ts_test <-
  household_ts |> 
  filter(year > 2014)
```


### Double moving average with N = 4

```{r}
N <- 4

household_double_ma <-
  household_ts_train |> 
  mutate(
    ma = slider::slide_mean(cnt, before = N - 1, after = 0, complete = TRUE),
    ma_double = slider::slide_mean(ma, before = N - 1, after = 0, complete = TRUE)
  )

household_double_ma
```

Visualize results.

```{r}
household_double_ma |> 
  pivot_longer(c(cnt, ma, ma_double), names_to = "statistics") |> 
  autoplot(value)
```


### Estimate a slope

Take the latest moving average and double moving average.

```{r}
latest <- 
  household_double_ma |> 
  slice_tail(n = 1)

latest
```

Compute a slope

```{r}
b <- (latest$ma - latest$ma_double) / (N - 1) * 2
b
```


### Prediction

```{r}
household_ts_test |> 
  mutate(
    ma = latest$ma,
    ma_double = 2 * latest$ma - latest$ma_double + (year - latest$year) * b
  )
```


## Examples 1.3 - 1.4

### Load data

```{r}
patent <- 
  read_excel("data/J02.xlsx") |> 
  rename(cnt = `#patents`)
```

### Convert to time-series data

```{r}
patent_ts <-
  patent |> 
  as_tsibble(index = year)

patent_ts
```


### Train/test split

```{r}
patent_ts_train <-
  patent_ts |> 
  filter(year <= 2013)

patent_ts_test <- 
  patent_ts |> 
  filter(year > 2013)
```

### Example 1.3: Double exponential smoothing with $\alpha = 0.2$

#### Smoothing on training data

```{r}
alpha <- 0.2

ets_step <- function(x, y, alpha) {
  stopifnot(alpha >= 0)
  stopifnot(alpha <= 1)
  (1 - alpha) * x + alpha * y
}

patent_ets <- 
  patent_ts_train |> 
  mutate(
    es = accumulate(cnt, ets_step, alpha = alpha),
    es_double = accumulate(es, ets_step, alpha = alpha)
  )

patent_ets
```


Visualize the smoothing results.

```{r}
patent_ets |> 
  pivot_longer(c(cnt, es, es_double), names_to = "statistics") |> 
  autoplot(value)
```


#### Estimate coefficients

Take the last training time point.

```{r}
latest <- 
  patent_ets |> 
  slice_tail(n = 1)

n_train <- nrow(patent_ets)
latest_year <- latest$year
```

Estimate slope `b`.

```{r}
b <- alpha / (1 - alpha) * (latest$es - latest$es_double)
b
```

Estimate constant `c`.

```{r}
c <- 2 * latest$es - latest$es_double - b * n_train
c
```


#### Prediction

```{r}
patent_ts_test |> 
  mutate(
    forecast = c + b * (n_train + (year - latest_year)),
    forecast_error = cnt - forecast
  )
```


### Example 1.4: Holt's linear trend method

#### Smoothing on training data

Implement a function to update `L` and `b` in each iteration (i.e. each additional observation).

```{r}
holt_step <- function(param, x, alpha, beta) {
  L <- param$L
  b <- param$b

  L_new = alpha * x + (1 - alpha) * (L + b)
  b_new = beta * (L_new - L) + (1 - beta) * b

  res <- list(L = L_new, b = b_new)

  res
}
```

Set parameters for Holt smoothing.

```{r}
alpha <- 0.2
beta <- 0.2
```

Initialize `L` and `b` values.

```{r}
L1 <- patent_ts_train$cnt[1]
b1 <- patent_ts_train$cnt[2] - patent_ts_train$cnt[1]
```

Compute Holt smoothing over training time periods.

```{r}
patent_holt <- 
  patent_ts_train |> 
  mutate(
    es_double = accumulate(patent_ts_train$cnt[-1], holt_step, .init = list(L = L1, b = b1), alpha = alpha, beta = beta)
  ) |> 
  unnest_wider(es_double) |> 
  as_tsibble(index = year)

patent_holt
```

:::{.callout-note}
`unnest_wider()` returns `tibble` object, not `tsibble` object. sCall `as_tsibble()` to convert the results back to `tsibble` object.
:::

Visualize smoothing results.

```{r}
patent_holt |> 
  pivot_longer(c(cnt, L), names_to = "statistics") |> 
  autoplot(value)
```


#### Prediction

Obtain the latest value of `L` and `b`.

```{r}
latest <- 
  patent_holt |> 
  slice_tail(n = 1)

latest
```

Make a prediction on test data with linear trend assumption.

```{r}
patent_ts_test |> 
  mutate(
    forecast = latest$L + latest$b * (year - latest$year),
    forecast_error = cnt - forecast
  )
```


#### Use `{fable}`

Let us use `ETS()` from `{fable}`. The approach is explained in [Forecasting: Principles and Practice](https://otexts.com/fpp3/holt.html) by Rob J Hyndman and George Athanasopoulos.

First, let us use the same `alpha` and `beta` that were used in the previous section.

```{r}
alpha <- 0.2
beta <- 0.2

fit <- 
  patent_ts_train |> 
  model(ANN = ETS(cnt ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")))

fitted(fit)
```

Let us print estimated levels and slopes in training data

```{r}
fit$ANN[[1]]$fit$states
```

The results are different from previous section, because of different initialization of level and slope parameter value.

```{r}
fit |> 
  select(ANN) |> 
  report()
```

Let us create a forecast.

```{r}
fit |> 
  forecast(h = 3)
```


Now, call `ETS()` without specifying `alpha` and `beta` argument, so it finds the optimal value for fitting.

```{r}
fit_opt <- 
  patent_ts_train |> 
  model(ANN = ETS(cnt ~ error("A") + trend("A") + season("N")))

fitted(fit_opt)
```

```{r}
fit_opt |> 
  select(ANN) |> 
  report()
```

```{r}
fit_opt |> 
  forecast(h = 3)
```




## Example 1.5

### Load data

```{r}
gas_consumption <- read_excel("data/J03.xlsx", skip = 1) |> 
  fill(year, .direction = "down") |> 
  rename(consumption = comsumption) # fix typo in column name

gas_consumption
```

### Convert to tsibble object

```{r}
gas_consumption_ts <- 
  gas_consumption |> 
  mutate(year_month = make_yearmonth(year, month), .before = 1L) |> 
  select(!c(year, month)) |> 
  as_tsibble(index = year_month)

gas_consumption_ts
```


### Visualize seasonal pattern

Call `gg_season()` from `{feasts}` package to visualize seasonal pattern of the variable of interest.

```{r}
gas_consumption_ts |> 
  gg_season(consumption)
```

### Train/test data split

```{r}
gas_consumption_ts_train <- 
  gas_consumption_ts |> 
  filter(year_month < make_yearmonth(2017, 1))

gas_consumption_ts_test <- 
  gas_consumption_ts |> 
  filter(year_month >= make_yearmonth(2017, 1))
```


### Holt-Winters' multiplicative method

#### Initialization

Extract first 2 years data.

```{r}
m <- 12
r <- 2

gas_consumption_ts_init <-
  gas_consumption_ts_train |> 
  slice_head(n = m * r)
```

Compute an initial slope parameter value.

```{r}
b <- 
  gas_consumption_ts_init |> 
  mutate(slope = difference(consumption, lag = 12) / m) |> 
  pull(slope) |> 
  mean(na.rm= TRUE)

b
```

Compute initial seasonal factor values.

```{r}
s <-
  gas_consumption_ts_init |> 
  group_by(year(year_month)) |> 
  mutate(seasonal = consumption / mean(consumption)) |> 
  group_by(month(year_month)) |> 
  mutate(seasonal = mean(seasonal)) |> 
  ungroup() |> 
  select(year_month, consumption, seasonal) |> 
  slice_head(n = m) |> 
  pull(seasonal)

s
```

Compute initial level.

```{r}
l <- mean(gas_consumption_ts_init$consumption)
l
```


#### Smoothing on training data

```{r}
n_train <- nrow(gas_consumption_ts_train)
b_vec <- vector("numeric", length = m + n_train)
s_vec <- vector("numeric", length = m + n_train)
l_vec <- vector("numeric", length = m + n_train)
x_vec <- vector("numeric", length = m + n_train)

b_vec[m] <- b
s_vec[1:m] <- s
l_vec[m] <- l
x_vec[m + seq_len(n_train)] <- gas_consumption_ts_train$consumption
```

```{r}
alpha <- 0.1
beta <- 0.1
gamma <- 0.1

for (t in (m + 1):length(b_vec)) {
  l_vec[t] <- alpha * x_vec[t] / s_vec[t - m] + (1 - alpha) * (l_vec[t - 1] + b_vec[t - 1])
  b_vec[t] <- beta * (l_vec[t] - l_vec[t - 1]) + (1 - beta) * b_vec[t - 1]
  s_vec[t] <- gamma * (x_vec[t] / l_vec[t]) + (1 - gamma) * s_vec[t - m]
}
```


```{r}
gas_consumption_winters <- 
  gas_consumption_ts_train |> 
  mutate(
    l = l_vec[-seq_len(m)],
    b = b_vec[-seq_len(m)],
    s = s_vec[-seq_len(m)]
  )

gas_consumption_winters |> 
  tail(n = m)
```


#### Forecast

```{r}
l_latest <- 
  gas_consumption_winters |> 
  slice_tail(n = 1) |> 
  pull(l)

b_latest <- 
  gas_consumption_winters |> 
  slice_tail(n = 1) |> 
  pull(b)

s_latest <- 
  gas_consumption_winters |> 
  slice_tail(n = m) |> 
  pull(s)

month_latest <- 
  gas_consumption_winters |> 
  slice_tail(n = 1) |> 
  pull(year_month)
```


```{r}
gas_consumption_ts_test |> 
  mutate(
    k = year_month - month_latest,
    forecast = (l_latest + b_latest * k) * s_latest[(k - 1) %% m + 1],
    forecast_error = consumption - forecast
  )
```

