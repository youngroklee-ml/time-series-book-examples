# Smoothing

```{r}
library(tidyverse)
library(tsibble) # time series data frame wrangling
library(fable)   # forecasting models
library(feasts)  # feature extraction, statistics, visualization for time series data
library(readxl)
```

## Example 1.1

### Data

Create a data frame.

```{r}
forest_fire <- tribble(
  ~year, ~cnt,
  2006, 369,
  2007, 418,
  2008, 389,
  2009, 570,
  2010, 282,
  2011, 277,
  2012, 197,
  2013, 296,
  2014, 492,
  2015, 623,
  2016, 391
)
```

### Convert to time-series data

Convert the data frame to time series data frame (`tsibble`) object. You must set `index` with a column that represents timepoints for the series. Please note that `tsibble` automatically notice that the index is year and that the series is regular yearly series.

```{r}
forest_fire_ts <-
  forest_fire |>
  as_tsibble(index = year)

forest_fire_ts
```


### Moving average

Compute moving average by calling `slider::slide_mean()`. Set `complete = TRUE` to return missing value `NA` when there are missing observations in the sliding window.

```{r}
forest_fire_ma <-
  forest_fire_ts |>
  mutate(
    ma3 = slider::slide_mean(cnt, before = 2, after = 0, complete = TRUE),
    ma6 = slider::slide_mean(cnt, before = 5, after = 0, complete = TRUE)
  )

forest_fire_ma
```

Now, `forest_fire_ma` is a time series data frame with three series: original value `cnt`, 3-yr moving average `ma3`, and 6-yr moving average `ma6`. 


### Visualization

Covert this to a long form by calling `pivot_longer()`. The resulting time series data frame will have `key` that is a label of each series.

```{r}
forest_fire_ma_long <- 
  forest_fire_ma |>
  pivot_longer(c(cnt, ma3, ma6), names_to = "statistics")

forest_fire_ma_long
```


Visualize time series data. Call `autoplot()` with measurement variable name to draws line plot by each `key`.

```{r}
forest_fire_ma_long |> 
  autoplot(value)
```


## Example 1.2

### Load data

```{r}
household <- 
  read_excel("data/J01.xlsx", skip = 1) |> 
  rename(cnt = `#households`)
```

### Convert to time-series data

```{r}
household_ts <-
  household |> 
  as_tsibble(index = year)

household_ts
```


### Train/test split

```{r}
household_ts_train <-
  household_ts |> 
  filter(year <= 2014)

household_ts_test <-
  household_ts |> 
  filter(year > 2014)
```


### Double moving average with N = 4

```{r}
N <- 4

household_double_ma <-
  household_ts_train |> 
  mutate(
    ma = slider::slide_mean(cnt, before = N - 1, after = 0, complete = TRUE),
    ma_double = slider::slide_mean(ma, before = N - 1, after = 0, complete = TRUE)
  )

household_double_ma
```

Visualize results.

```{r}
household_double_ma |> 
  pivot_longer(c(cnt, ma, ma_double), names_to = "statistics") |> 
  autoplot(value)
```


### Estimate a slope

Take the latest moving average and double moving average.

```{r}
latest <- 
  household_double_ma |> 
  slice_tail(n = 1)

latest
```

Compute a slope

```{r}
b <- (latest$ma - latest$ma_double) / (N - 1) * 2
b
```


### Prediction

```{r}
household_ts_test |> 
  mutate(
    ma = latest$ma,
    ma_double = 2 * latest$ma - latest$ma_double + (year - latest$year) * b
  )
```


## Examples 1.3 - 1.4

### Load data

```{r}
patent <- 
  read_excel("data/J02.xlsx") |> 
  rename(cnt = `#patents`)
```

### Convert to time-series data

```{r}
patent_ts <-
  patent |> 
  as_tsibble(index = year)

patent_ts
```


### Train/test split

```{r}
patent_ts_train <-
  patent_ts |> 
  filter(year <= 2013)

patent_ts_test <- 
  patent_ts |> 
  filter(year > 2013)
```

### Example 1.3: Double exponential smoothing with $\alpha = 0.2$

#### Smoothing on training data

```{r}
alpha <- 0.2

ets_step <- function(x, y, alpha) {
  stopifnot(alpha >= 0)
  stopifnot(alpha <= 1)
  (1 - alpha) * x + alpha * y
}

patent_ets <- 
  patent_ts_train |> 
  mutate(
    es = accumulate(cnt, ets_step, alpha = alpha),
    es_double = accumulate(es, ets_step, alpha = alpha)
  )

patent_ets
```


Visualize the smoothing results.

```{r}
patent_ets |> 
  pivot_longer(c(cnt, es, es_double), names_to = "statistics") |> 
  autoplot(value)
```


#### Estimate coefficients

Take the last training time point.

```{r}
latest <- 
  patent_ets |> 
  slice_tail(n = 1)

n_train <- nrow(patent_ets)
latest_year <- latest$year
```

Estimate slope `b`.

```{r}
b <- alpha / (1 - alpha) * (latest$es - latest$es_double)
b
```

Estimate constant `c`.

```{r}
c <- 2 * latest$es - latest$es_double - b * n_train
c
```


#### Prediction

```{r}
patent_ts_test |> 
  mutate(
    forecast = c + b * (n_train + (year - latest_year)),
    forecast_error = cnt - forecast
  )
```


### Example 1.4: Holt linear

#### Smoothing on training data

Implement a function to update `L` and `b` in each iteration (i.e. each additional observation).

```{r}
holt_step <- function(param, x, alpha, beta) {
  L <- param$L
  b <- param$b

  L_new = alpha * x + (1 - alpha) * (L + b)
  b_new = beta * (L_new - L) + (1 - beta) * b

  res <- list(L = L_new, b = b_new)

  res
}
```

Set parameters for Holt smoothing.

```{r}
alpha <- 0.2
beta <- 0.2
```

Initialize `L` and `b` values.

```{r}
L1 <- patent_ts_train$cnt[1]
b1 <- patent_ts_train$cnt[2] - patent_ts_train$cnt[1]
```

Compute Holt smoothing over training time periods.

```{r}
patent_holt <- 
  patent_ts_train |> 
  mutate(
    es_double = accumulate(patent_ts_train$cnt[-1], holt_step, .init = list(L = L1, b = b1), alpha = alpha, beta = beta)
  ) |> 
  unnest_wider(es_double)
```


#### Prediction

Obtain the latest value of `L` and `b`.

```{r}
latest <- 
  patent_holt |> 
  slice_tail(n = 1)

latest
```

Make a prediction on test data with linear trend assumption.

```{r}
patent_ts_test |> 
  mutate(
    forecast = latest$L + latest$b * (year - latest$year),
    forecast_error = cnt - forecast
  )
```


